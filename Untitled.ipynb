{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1002dc67-430f-4397-9c52-c4fdc4a8dbe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTransformer (From Scratch) - Version GPU avec Optimiseur Configurable\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELLULE 1: Titre\n",
    "# ============================================\n",
    "\"\"\"\n",
    "Transformer (From Scratch) - Version GPU avec Optimiseur Configurable\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c66b1213-38ac-405e-820c-92138ac0458b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELLULE 2: Imports\n",
    "# ============================================\n",
    "# gere les structures de donnees de bases, le calcul du gradient automatique\n",
    "import torch\n",
    "# contient les blocs de construction des RN, couches pre-construites\n",
    "import torch.nn as nn\n",
    "# contient les algos d'optimisation\n",
    "import torch.optim as optim\n",
    "# pour creer les dataloaders (gere les flux de donnees)\n",
    "import torch.utils.data as data\n",
    "# contient les fonctions mathematiques\n",
    "import math\n",
    "# pour copier les onjets\n",
    "import copy\n",
    "import time\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33f456ca-eaca-48bf-99d1-fa683a18b254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üñ•Ô∏è  DEVICE UTILIS√â: cpu\n",
      "============================================================\n",
      "Mode CPU activ√©\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELLULE 3: Configuration du device avec choix GPU/CPU\n",
    "# ============================================\n",
    "# CHOIX DU DEVICE: Modifiez ici pour forcer CPU ou GPU\n",
    "FORCE_DEVICE = \"cpu\"  # Options: \"auto\", \"cpu\", \"cuda\"\n",
    "\n",
    "if FORCE_DEVICE == \"auto\":\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "elif FORCE_DEVICE == \"cuda\":\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        print(\"CUDA non disponible, utilisation du CPU\")\n",
    "        device = torch.device(\"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\"üñ•Ô∏è  DEVICE UTILIS√â: {device}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    print(f\"‚úì GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"‚úì M√©moire totale: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "    print(f\"‚úì M√©moire disponible: {(torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_allocated(0)) / 1024**3:.2f} GB\")\n",
    "else:\n",
    "    print(\"Mode CPU activ√©\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5636634-8944-4dfe-b7c3-9bf094e06d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELLULE 4: Classe AttentionMultiTetes\n",
    "# ============================================\n",
    "class AttentionMultiTetes(nn.Module):\n",
    "    def __init__(self, d_modele, nb_tetes):\n",
    "        super(AttentionMultiTetes, self).__init__()\n",
    "        # S'assurer que la dimension du mod√®le (d_modele) est divisible par le nombre de t√™tes\n",
    "        assert d_modele % nb_tetes == 0, \"d_modele doit √™tre divisible par nb_tetes\"\n",
    "        \n",
    "        # Initialisation des dimensions\n",
    "        self.d_modele = d_modele # Dimension du mod√®le\n",
    "        self.nb_tetes = nb_tetes # Nombre de t√™tes d'attention\n",
    "        self.d_k = d_modele // nb_tetes # Dimension des cl√©s, requ√™tes et valeurs de chaque t√™te\n",
    "        \n",
    "        # Couches lin√©aires pour la transformation des entr√©es\n",
    "        self.W_q = nn.Linear(d_modele, d_modele) # Transformation des Requ√™tes (Query)\n",
    "        self.W_k = nn.Linear(d_modele, d_modele) # Transformation des Cl√©s (Key)\n",
    "        self.W_v = nn.Linear(d_modele, d_modele) # Transformation des Valeurs (Value)\n",
    "        self.W_o = nn.Linear(d_modele, d_modele) # Transformation de Sortie (Output)\n",
    "    \n",
    "    def attention_produit_scalaire_normalisee(self, Q, K, V, masque=None):\n",
    "        # Calcul des scores d'attention\n",
    "        scores_attn = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        \n",
    "        # Appliquer le masque si fourni (utile pour ignorer le rembourrage/padding)\n",
    "        if masque is not None:\n",
    "            scores_attn = scores_attn.masked_fill(masque == 0, -1e9)\n",
    "        \n",
    "        # Application du Softmax pour obtenir les probabilit√©s d'attention\n",
    "        probs_attn = torch.softmax(scores_attn, dim=-1)\n",
    "        \n",
    "        # Multiplier par les valeurs pour obtenir la sortie finale\n",
    "        sortie = torch.matmul(probs_attn, V)\n",
    "        return sortie\n",
    "    \n",
    "    def separer_tetes(self, x):\n",
    "        # Redimensionner l'entr√©e pour avoir plusieurs t√™tes d'attention\n",
    "        taille_batch, long_seq, d_modele = x.size()\n",
    "        return x.view(taille_batch, long_seq, self.nb_tetes, self.d_k).transpose(1, 2)\n",
    "    \n",
    "    def combiner_tetes(self, x):\n",
    "        # Combiner les t√™tes multiples pour revenir √† la forme originale\n",
    "        taille_batch, _, long_seq, d_k = x.size()\n",
    "        return x.transpose(1, 2).contiguous().view(taille_batch, long_seq, self.d_modele)\n",
    "    \n",
    "    def forward(self, Q, K, V, masque=None):\n",
    "        # Appliquer les transformations lin√©aires et s√©parer les t√™tes\n",
    "        Q = self.separer_tetes(self.W_q(Q))\n",
    "        K = self.separer_tetes(self.W_k(K))\n",
    "        V = self.separer_tetes(self.W_v(V))\n",
    "        \n",
    "        # Effectuer l'attention par produit scalaire normalis√©e\n",
    "        sortie_attn = self.attention_produit_scalaire_normalisee(Q, K, V, masque)\n",
    "        \n",
    "        # Combiner les t√™tes et appliquer la transformation de sortie finale\n",
    "        sortie = self.W_o(self.combiner_tetes(sortie_attn))\n",
    "        return sortie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b78014e-6647-4499-8402-aee2749b648d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELLULE 5: Classe ReseauNeuronesPositionnel\n",
    "# ============================================\n",
    "class ReseauNeuronesPositionnel(nn.Module):\n",
    "    def __init__(self, d_modele, d_ff):\n",
    "        super(ReseauNeuronesPositionnel, self).__init__()\n",
    "        # Premi√®re couche lin√©aire (expansion de la dimension)\n",
    "        self.fc1 = nn.Linear(d_modele, d_ff)\n",
    "        # Seconde couche lin√©aire (retour √† la dimension originale du mod√®le)\n",
    "        self.fc2 = nn.Linear(d_ff, d_modele)\n",
    "        # Fonction d'activation non-lin√©aire\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Passage dans la premi√®re couche, activation ReLU, puis seconde couche\n",
    "        return self.fc2(self.relu(self.fc1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c497413b-ea2f-439b-b113-ffb4ad4a51d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELLULE 6: Classe EncodagePositionnel\n",
    "# ============================================\n",
    "class EncodagePositionnel(nn.Module):\n",
    "    def __init__(self, d_modele, long_max_seq):\n",
    "        super(EncodagePositionnel, self).__init__()\n",
    "        \n",
    "        # Cr√©ation d'une matrice d'encodage positionnel (pe) remplie de z√©ros\n",
    "        pe = torch.zeros(long_max_seq, d_modele)\n",
    "        \n",
    "        # Cr√©ation d'un vecteur de positions (0, 1, 2, ..., long_max_seq)\n",
    "        position = torch.arange(0, long_max_seq, dtype=torch.float).unsqueeze(1)\n",
    "        \n",
    "        # Calcul du terme de division pour les fr√©quences sinus et cosinus\n",
    "        terme_div = torch.exp(torch.arange(0, d_modele, 2).float() * -(math.log(10000.0) / d_modele))\n",
    "        \n",
    "        # Application de la fonction sinus aux indices pairs (0, 2, 4...)\n",
    "        pe[:, 0::2] = torch.sin(position * terme_div)\n",
    "        \n",
    "        # Application de la fonction cosinus aux indices impairs (1, 3, 5...)\n",
    "        pe[:, 1::2] = torch.cos(position * terme_div)\n",
    "        \n",
    "        # Enregistrer 'pe' comme un buffer (ne sera pas consid√©r√© comme un param√®tre entra√Ænable)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Ajoute l'encodage positionnel aux plongements (embeddings) d'entr√©e\n",
    "        return x + self.pe[:, :x.size(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3ec23ea-ec02-4586-8a82-652aaee0c9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELLULE 7: Classe CoucheEncodeur\n",
    "# ============================================\n",
    "class CoucheEncodeur(nn.Module):\n",
    "    def __init__(self, d_modele, nb_tetes, d_ff, dropout):\n",
    "        super(CoucheEncodeur, self).__init__()\n",
    "        # Auto-attention multi-t√™tes\n",
    "        self.auto_attn = AttentionMultiTetes(d_modele, nb_tetes)\n",
    "        # R√©seau de neurones positionnel (Feed-Forward)\n",
    "        self.reseau_positionnel = ReseauNeuronesPositionnel(d_modele, d_ff)\n",
    "        # Couches de normalisation\n",
    "        self.norm1 = nn.LayerNorm(d_modele)\n",
    "        self.norm2 = nn.LayerNorm(d_modele)\n",
    "        # Couche de dropout pour la r√©gularisation\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x, masque):\n",
    "        # √âtape 1 : Auto-attention et connexion r√©siduelle suivie d'une normalisation\n",
    "        sortie_attn = self.auto_attn(x, x, x, masque)\n",
    "        x = self.norm1(x + self.dropout(sortie_attn))\n",
    "        \n",
    "        # √âtape 2 : R√©seau Feed-Forward et connexion r√©siduelle suivie d'une normalisation\n",
    "        sortie_ff = self.reseau_positionnel(x)\n",
    "        x = self.norm2(x + self.dropout(sortie_ff))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4320dc22-7654-4ef6-b81f-a3ce60238727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELLULE 8: Classe CoucheDecodeur\n",
    "# ============================================\n",
    "class CoucheDecodeur(nn.Module):\n",
    "    def __init__(self, d_modele, nb_tetes, d_ff, dropout):\n",
    "        super(CoucheDecodeur, self).__init__()\n",
    "        # Auto-attention pour les tokens de la cible (d√©j√† g√©n√©r√©s)\n",
    "        self.auto_attn = AttentionMultiTetes(d_modele, nb_tetes)\n",
    "        # Attention crois√©e pour regarder la sortie de l'encodeur\n",
    "        self.attn_croisee = AttentionMultiTetes(d_modele, nb_tetes)\n",
    "        # R√©seau de neurones positionnel (Feed-Forward)\n",
    "        self.reseau_positionnel = ReseauNeuronesPositionnel(d_modele, d_ff)\n",
    "        \n",
    "        # Couches de normalisation\n",
    "        self.norm1 = nn.LayerNorm(d_modele)\n",
    "        self.norm2 = nn.LayerNorm(d_modele)\n",
    "        self.norm3 = nn.LayerNorm(d_modele)\n",
    "        # Couche de dropout pour la r√©gularisation\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x, sortie_encodeur, masque_src, masque_tgt):\n",
    "        # √âtape 1 : Auto-attention sur la cible avec masque (pour ne pas voir le futur)\n",
    "        sortie_auto_attn = self.auto_attn(x, x, x, masque_tgt)\n",
    "        x = self.norm1(x + self.dropout(sortie_auto_attn))\n",
    "        \n",
    "        # √âtape 2 : Attention crois√©e (Requ√™te vient du d√©codeur, Cl√©/Valeur de l'encodeur)\n",
    "        sortie_attn_croisee = self.attn_croisee(x, sortie_encodeur, sortie_encodeur, masque_src)\n",
    "        x = self.norm2(x + self.dropout(sortie_attn_croisee))\n",
    "        \n",
    "        # √âtape 3 : R√©seau Feed-Forward\n",
    "        sortie_ff = self.reseau_positionnel(x)\n",
    "        x = self.norm3(x + self.dropout(sortie_ff))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6dbeb32-3b6a-4d3e-a71d-2d194fae29f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELLULE 9: Classe Transformer\n",
    "# ============================================\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, taille_vocab_src, taille_vocab_tgt, d_modele, nb_tetes, nb_couches, d_ff, long_max_seq, dropout):\n",
    "        super(Transformer, self).__init__()\n",
    "        # Couches de plongement (embeddings) pour la source et la cible\n",
    "        self.plongement_encodeur = nn.Embedding(taille_vocab_src, d_modele)\n",
    "        self.plongement_decodeur = nn.Embedding(taille_vocab_tgt, d_modele)\n",
    "        # Module d'encodage positionnel\n",
    "        self.encodage_positionnel = EncodagePositionnel(d_modele, long_max_seq)\n",
    "        \n",
    "        # Listes de couches pour l'encodeur et le d√©codeur\n",
    "        self.couches_encodeur = nn.ModuleList([CoucheEncodeur(d_modele, nb_tetes, d_ff, dropout) for _ in range(nb_couches)])\n",
    "        self.couches_decodeur = nn.ModuleList([CoucheDecodeur(d_modele, nb_tetes, d_ff, dropout) for _ in range(nb_couches)])\n",
    "        \n",
    "        # Couche lin√©aire finale pour la pr√©diction des mots\n",
    "        self.fc = nn.Linear(d_modele, taille_vocab_tgt)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def generer_masque(self, src, tgt):\n",
    "        # Masque pour ignorer les jetons de rembourrage (padding) dans la source\n",
    "        masque_src = (src != 0).unsqueeze(1).unsqueeze(2)\n",
    "        # Masque pour ignorer le rembourrage dans la cible\n",
    "        masque_tgt = (tgt != 0).unsqueeze(1).unsqueeze(3)\n",
    "        \n",
    "        # Masque triangulaire pour emp√™cher le d√©codeur de regarder les mots futurs\n",
    "        long_seq = tgt.size(1)\n",
    "        masque_causal = (1 - torch.triu(torch.ones(1, long_seq, long_seq, device=tgt.device), diagonal=1)).bool()\n",
    "        masque_tgt = masque_tgt & masque_causal\n",
    "        \n",
    "        return masque_src, masque_tgt\n",
    "    \n",
    "    def forward(self, src, tgt):\n",
    "        # 1. G√©n√©ration des masques\n",
    "        masque_src, masque_tgt = self.generer_masque(src, tgt)\n",
    "        \n",
    "        # 2. Pr√©paration des entr√©es (Embedding + Encodage Positionnel)\n",
    "        src_embedded = self.dropout(self.encodage_positionnel(self.plongement_encodeur(src)))\n",
    "        tgt_embedded = self.dropout(self.encodage_positionnel(self.plongement_decodeur(tgt)))\n",
    "        \n",
    "        # 3. Passage √† travers les couches de l'encodeur\n",
    "        sortie_encodeur = src_embedded\n",
    "        for couche_enc in self.couches_encodeur:\n",
    "            sortie_encodeur = couche_enc(sortie_encodeur, masque_src)\n",
    "        \n",
    "        # 4. Passage √† travers les couches du d√©codeur\n",
    "        sortie_decodeur = tgt_embedded\n",
    "        for couche_dec in self.couches_decodeur:\n",
    "            sortie_decodeur = couche_dec(sortie_decodeur, sortie_encodeur, masque_src, masque_tgt)\n",
    "        \n",
    "        # 5. Projection finale vers le vocabulaire de sortie\n",
    "        output = self.fc(sortie_decodeur)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4531d117-aeec-4311-9c7f-5bf19e14c718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "‚öôÔ∏è  CONFIGURATION DES HYPERPARAM√àTRES\n",
      "============================================================\n",
      "Configuration CPU (r√©duite)\n",
      "\n",
      "Param√®tres du mod√®le:\n",
      "  - Vocabulaire source: 5000\n",
      "  - Vocabulaire cible: 5000\n",
      "  - Dimension mod√®le: 256\n",
      "  - Nombre de t√™tes: 4\n",
      "  - Nombre de couches: 3\n",
      "  - Dimension FF: 1024\n",
      "  - Longueur max s√©quence: 5000\n",
      "  - Dropout: 0.1\n",
      "\n",
      "Param√®tres d'entra√Ænement:\n",
      "  - Taille batch: 4\n",
      "  - Longueur s√©quence: 128\n",
      "  - M√©moire estim√©e pour l'attention: ~0.25 MB\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELLULE 10: Configuration des hyperparam√®tres\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚öôÔ∏è  CONFIGURATION DES HYPERPARAM√àTRES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Configuration des hyperparam√®tres du mod√®le\n",
    "taille_vocab_src = 5000\n",
    "taille_vocab_tgt = 5000\n",
    "d_modele = 256\n",
    "nb_tetes = 4\n",
    "nb_couches = 3\n",
    "d_ff = 1024\n",
    "long_max_seq = 5000  # Longueur maximale support√©e\n",
    "dropout = 0.1\n",
    "\n",
    "# ‚öôÔ∏è PARAM√àTRES D'ENTRA√éNEMENT OPTIMIS√âS POUR GPU\n",
    "if device.type == \"cuda\":\n",
    "    taille_batch = 32  # Batch optimis√© pour GPU\n",
    "    longueur_seq = 512  # S√©quence plus longue pour GPU\n",
    "    print(\"‚úì Configuration GPU optimis√©e\")\n",
    "else:\n",
    "    taille_batch = 4\n",
    "    longueur_seq = 128\n",
    "    print(\"Configuration CPU (r√©duite)\")\n",
    "\n",
    "print(f\"\\nParam√®tres du mod√®le:\")\n",
    "print(f\"  - Vocabulaire source: {taille_vocab_src}\")\n",
    "print(f\"  - Vocabulaire cible: {taille_vocab_tgt}\")\n",
    "print(f\"  - Dimension mod√®le: {d_modele}\")\n",
    "print(f\"  - Nombre de t√™tes: {nb_tetes}\")\n",
    "print(f\"  - Nombre de couches: {nb_couches}\")\n",
    "print(f\"  - Dimension FF: {d_ff}\")\n",
    "print(f\"  - Longueur max s√©quence: {long_max_seq}\")\n",
    "print(f\"  - Dropout: {dropout}\")\n",
    "\n",
    "print(f\"\\nParam√®tres d'entra√Ænement:\")\n",
    "print(f\"  - Taille batch: {taille_batch}\")\n",
    "print(f\"  - Longueur s√©quence: {longueur_seq}\")\n",
    "\n",
    "# Calcul de la m√©moire estim√©e\n",
    "memoire_estimee_mb = (taille_batch * longueur_seq * longueur_seq * 4) / (1024**2)\n",
    "print(f\"  - M√©moire estim√©e pour l'attention: ~{memoire_estimee_mb:.2f} MB\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f70044f-268d-42f4-bb1f-f714c29058c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üî® Initialisation du Transformer...\n",
      "‚úì Mod√®le initialis√© en 0.10s\n",
      "‚úì Nombre de param√®tres: 9,374,600\n",
      "‚úì Taille du mod√®le: ~35.76 MB\n",
      "\n",
      "üìä G√©n√©ration des donn√©es d'entra√Ænement...\n",
      "‚úì Donn√©es g√©n√©r√©es avec succ√®s!\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELLULE 11: Initialisation du mod√®le\n",
    "# ============================================\n",
    "print(\"\\nüî® Initialisation du Transformer...\")\n",
    "debut_init = time.time()\n",
    "\n",
    "transformer = Transformer(\n",
    "    taille_vocab_src,\n",
    "    taille_vocab_tgt,\n",
    "    d_modele,\n",
    "    nb_tetes,\n",
    "    nb_couches,\n",
    "    d_ff,\n",
    "    long_max_seq,\n",
    "    dropout\n",
    ").to(device)\n",
    "\n",
    "fin_init = time.time()\n",
    "nb_parametres = sum(p.numel() for p in transformer.parameters())\n",
    "\n",
    "print(f\"‚úì Mod√®le initialis√© en {fin_init - debut_init:.2f}s\")\n",
    "print(f\"‚úì Nombre de param√®tres: {nb_parametres:,}\")\n",
    "print(f\"‚úì Taille du mod√®le: ~{nb_parametres * 4 / (1024**2):.2f} MB\")\n",
    "\n",
    "# G√©n√©ration de donn√©es d'exemple al√©atoires\n",
    "print(\"\\nüìä G√©n√©ration des donn√©es d'entra√Ænement...\")\n",
    "src_donnees = torch.randint(1, taille_vocab_src, (taille_batch, longueur_seq)).to(device)\n",
    "tgt_donnees = torch.randint(1, taille_vocab_tgt, (taille_batch, longueur_seq)).to(device)\n",
    "print(\"‚úì Donn√©es g√©n√©r√©es avec succ√®s!\")\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    memoire_modele = torch.cuda.memory_allocated(device) / (1024**2)\n",
    "    print(f\"‚úì M√©moire GPU utilis√©e: {memoire_modele:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6eb932e6-b887-41d1-abca-68b17393f2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CONFIGURATION DE L'OPTIMISEUR\n",
      "============================================================\n",
      "‚úì Optimiseur s√©lectionn√©: Adam\n",
      "‚úì Learning rate: 0.001\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELLULE 12: Configuration de l'optimiseur (CHOIX MULTIPLE)\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CONFIGURATION DE L'OPTIMISEUR\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# CHOISISSEZ VOTRE OPTIMISEUR ICI\n",
    "OPTIMISEUR_CHOISI = \"Adam\"  # Options: \"Adam\", \"SGD\", \"AdamW\", \"RMSprop\", \"Adagrad\"\n",
    "\n",
    "# Configuration des hyperparam√®tres d'optimisation\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Dictionnaire des optimiseurs disponibles\n",
    "optimiseurs_disponibles = {\n",
    "    \"Adam\": lambda: optim.Adam(\n",
    "        transformer.parameters(), \n",
    "        lr=learning_rate, \n",
    "        betas=(0.9, 0.98), \n",
    "        eps=1e-9\n",
    "    ),\n",
    "    \"AdamW\": lambda: optim.AdamW(\n",
    "        transformer.parameters(), \n",
    "        lr=learning_rate, \n",
    "        betas=(0.9, 0.98), \n",
    "        eps=1e-9,\n",
    "        weight_decay=0.01\n",
    "    ),\n",
    "    \"SGD\": lambda: optim.SGD(\n",
    "        transformer.parameters(), \n",
    "        lr=learning_rate, \n",
    "        momentum=0.9\n",
    "    ),\n",
    "    \"RMSprop\": lambda: optim.RMSprop(\n",
    "        transformer.parameters(), \n",
    "        lr=learning_rate, \n",
    "        alpha=0.99, \n",
    "        eps=1e-8\n",
    "    ),\n",
    "    \"Adagrad\": lambda: optim.Adagrad(\n",
    "        transformer.parameters(), \n",
    "        lr=learning_rate, \n",
    "        lr_decay=0\n",
    "    )\n",
    "}\n",
    "\n",
    "# Cr√©ation de l'optimiseur\n",
    "if OPTIMISEUR_CHOISI in optimiseurs_disponibles:\n",
    "    optimiser = optimiseurs_disponibles[OPTIMISEUR_CHOISI]()\n",
    "    print(f\"‚úì Optimiseur s√©lectionn√©: {OPTIMISEUR_CHOISI}\")\n",
    "    print(f\"‚úì Learning rate: {learning_rate}\")\n",
    "else:\n",
    "    print(f\"‚ùå Optimiseur '{OPTIMISEUR_CHOISI}' non reconnu!\")\n",
    "    print(f\"Options disponibles: {', '.join(optimiseurs_disponibles.keys())}\")\n",
    "    raise ValueError(f\"Optimiseur invalide: {OPTIMISEUR_CHOISI}\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33df1a32-407d-464c-af3d-fbeb761941fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELLULE 13: Fonction de chronom√©trage\n",
    "# ============================================\n",
    "def formater_temps(secondes):\n",
    "    \"\"\"Formate les secondes en format lisible\"\"\"\n",
    "    return str(timedelta(seconds=int(secondes)))\n",
    "\n",
    "def afficher_progression(epoch, nb_epochs, temps_ecoule, perte):\n",
    "    \"\"\"Affiche la progression avec temps √©coul√© et estim√©\"\"\"\n",
    "    temps_par_epoch = temps_ecoule / (epoch + 1)\n",
    "    temps_restant = temps_par_epoch * (nb_epochs - epoch - 1)\n",
    "    \n",
    "    barre_progression = \"‚ñà\" * int(30 * (epoch + 1) / nb_epochs)\n",
    "    barre_vide = \"‚ñë\" * (30 - int(30 * (epoch + 1) / nb_epochs))\n",
    "    pourcentage = 100 * (epoch + 1) / nb_epochs\n",
    "    \n",
    "    print(f\"[{barre_progression}{barre_vide}] {pourcentage:.1f}% | \"\n",
    "          f\"√âpoque: {epoch+1}/{nb_epochs} | \"\n",
    "          f\"Perte: {perte:.4f} | \"\n",
    "          f\" {formater_temps(temps_ecoule)} / ~{formater_temps(temps_ecoule + temps_restant)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d27e501-9a49-4d4c-a31b-b71ccef9954e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üöÄ D√âBUT DE L'ENTRA√éNEMENT\n",
      "============================================================\n",
      "Nombre d'√©poques: 150\n",
      "Optimiseur: Adam\n",
      "============================================================\n",
      "\n",
      "[‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 0.7% | √âpoque: 1/150 | Perte: 0.0082 |  0:00:00 / ~0:00:33\n",
      "[‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 1.3% | √âpoque: 2/150 | Perte: 0.0080 |  0:00:00 / ~0:00:31\n",
      "[‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 2.0% | √âpoque: 3/150 | Perte: 0.0080 |  0:00:00 / ~0:00:30\n",
      "[‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 2.7% | √âpoque: 4/150 | Perte: 0.0077 |  0:00:00 / ~0:00:30\n",
      "[‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 3.3% | √âpoque: 5/150 | Perte: 0.0079 |  0:00:01 / ~0:00:30\n",
      "[‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 4.0% | √âpoque: 6/150 | Perte: 0.0077 |  0:00:01 / ~0:00:30\n",
      "[‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 4.7% | √âpoque: 7/150 | Perte: 0.0074 |  0:00:01 / ~0:00:30\n",
      "[‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 5.3% | √âpoque: 8/150 | Perte: 0.0075 |  0:00:01 / ~0:00:30\n",
      "[‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 6.0% | √âpoque: 9/150 | Perte: 0.0075 |  0:00:01 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 6.7% | √âpoque: 10/150 | Perte: 0.0074 |  0:00:02 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 7.3% | √âpoque: 11/150 | Perte: 0.0070 |  0:00:02 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 8.0% | √âpoque: 12/150 | Perte: 0.0073 |  0:00:02 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 8.7% | √âpoque: 13/150 | Perte: 0.0070 |  0:00:02 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 9.3% | √âpoque: 14/150 | Perte: 0.0069 |  0:00:02 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 10.0% | √âpoque: 15/150 | Perte: 0.0070 |  0:00:03 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 10.7% | √âpoque: 16/150 | Perte: 0.0069 |  0:00:03 / ~0:00:31\n",
      "[‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 11.3% | √âpoque: 17/150 | Perte: 0.0069 |  0:00:03 / ~0:00:31\n",
      "[‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 12.0% | √âpoque: 18/150 | Perte: 0.0066 |  0:00:03 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 12.7% | √âpoque: 19/150 | Perte: 0.0066 |  0:00:03 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 13.3% | √âpoque: 20/150 | Perte: 0.0064 |  0:00:04 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 14.0% | √âpoque: 21/150 | Perte: 0.0063 |  0:00:04 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 14.7% | √âpoque: 22/150 | Perte: 0.0063 |  0:00:04 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 15.3% | √âpoque: 23/150 | Perte: 0.0063 |  0:00:04 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 16.0% | √âpoque: 24/150 | Perte: 0.0061 |  0:00:04 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 16.7% | √âpoque: 25/150 | Perte: 0.0060 |  0:00:05 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 17.3% | √âpoque: 26/150 | Perte: 0.0060 |  0:00:05 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 18.0% | √âpoque: 27/150 | Perte: 0.0060 |  0:00:05 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 18.7% | √âpoque: 28/150 | Perte: 0.0059 |  0:00:05 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 19.3% | √âpoque: 29/150 | Perte: 0.0058 |  0:00:05 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 20.0% | √âpoque: 30/150 | Perte: 0.0056 |  0:00:06 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 20.7% | √âpoque: 31/150 | Perte: 0.0057 |  0:00:06 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 21.3% | √âpoque: 32/150 | Perte: 0.0055 |  0:00:06 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 22.0% | √âpoque: 33/150 | Perte: 0.0055 |  0:00:06 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 22.7% | √âpoque: 34/150 | Perte: 0.0054 |  0:00:06 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 23.3% | √âpoque: 35/150 | Perte: 0.0054 |  0:00:07 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 24.0% | √âpoque: 36/150 | Perte: 0.0052 |  0:00:07 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 24.7% | √âpoque: 37/150 | Perte: 0.0052 |  0:00:07 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 25.3% | √âpoque: 38/150 | Perte: 0.0052 |  0:00:07 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 26.0% | √âpoque: 39/150 | Perte: 0.0051 |  0:00:07 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 26.7% | √âpoque: 40/150 | Perte: 0.0051 |  0:00:08 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 27.3% | √âpoque: 41/150 | Perte: 0.0051 |  0:00:08 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 28.0% | √âpoque: 42/150 | Perte: 0.0050 |  0:00:08 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 28.7% | √âpoque: 43/150 | Perte: 0.0049 |  0:00:08 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 29.3% | √âpoque: 44/150 | Perte: 0.0048 |  0:00:08 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 30.0% | √âpoque: 45/150 | Perte: 0.0048 |  0:00:09 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 30.7% | √âpoque: 46/150 | Perte: 0.0047 |  0:00:09 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 31.3% | √âpoque: 47/150 | Perte: 0.0048 |  0:00:09 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 32.0% | √âpoque: 48/150 | Perte: 0.0046 |  0:00:09 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 32.7% | √âpoque: 49/150 | Perte: 0.0046 |  0:00:09 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 33.3% | √âpoque: 50/150 | Perte: 0.0046 |  0:00:10 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 34.0% | √âpoque: 51/150 | Perte: 0.0045 |  0:00:10 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 34.7% | √âpoque: 52/150 | Perte: 0.0045 |  0:00:10 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 35.3% | √âpoque: 53/150 | Perte: 0.0044 |  0:00:10 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 36.0% | √âpoque: 54/150 | Perte: 0.0044 |  0:00:10 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 36.7% | √âpoque: 55/150 | Perte: 0.0042 |  0:00:11 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 37.3% | √âpoque: 56/150 | Perte: 0.0042 |  0:00:11 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 38.0% | √âpoque: 57/150 | Perte: 0.0042 |  0:00:11 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 38.7% | √âpoque: 58/150 | Perte: 0.0043 |  0:00:11 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 39.3% | √âpoque: 59/150 | Perte: 0.0042 |  0:00:11 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 40.0% | √âpoque: 60/150 | Perte: 0.0041 |  0:00:12 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 40.7% | √âpoque: 61/150 | Perte: 0.0041 |  0:00:12 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 41.3% | √âpoque: 62/150 | Perte: 0.0040 |  0:00:12 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 42.0% | √âpoque: 63/150 | Perte: 0.0039 |  0:00:12 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 42.7% | √âpoque: 64/150 | Perte: 0.0039 |  0:00:12 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 43.3% | √âpoque: 65/150 | Perte: 0.0038 |  0:00:12 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 44.0% | √âpoque: 66/150 | Perte: 0.0038 |  0:00:13 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 44.7% | √âpoque: 67/150 | Perte: 0.0037 |  0:00:13 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 45.3% | √âpoque: 68/150 | Perte: 0.0037 |  0:00:13 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 46.0% | √âpoque: 69/150 | Perte: 0.0036 |  0:00:13 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 46.7% | √âpoque: 70/150 | Perte: 0.0037 |  0:00:13 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 47.3% | √âpoque: 71/150 | Perte: 0.0036 |  0:00:14 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 48.0% | √âpoque: 72/150 | Perte: 0.0036 |  0:00:14 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 48.7% | √âpoque: 73/150 | Perte: 0.0034 |  0:00:14 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 49.3% | √âpoque: 74/150 | Perte: 0.0036 |  0:00:14 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 50.0% | √âpoque: 75/150 | Perte: 0.0034 |  0:00:14 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 50.7% | √âpoque: 76/150 | Perte: 0.0034 |  0:00:15 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 51.3% | √âpoque: 77/150 | Perte: 0.0033 |  0:00:15 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 52.0% | √âpoque: 78/150 | Perte: 0.0033 |  0:00:15 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 52.7% | √âpoque: 79/150 | Perte: 0.0033 |  0:00:15 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 53.3% | √âpoque: 80/150 | Perte: 0.0032 |  0:00:15 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 54.0% | √âpoque: 81/150 | Perte: 0.0032 |  0:00:16 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 54.7% | √âpoque: 82/150 | Perte: 0.0032 |  0:00:16 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 55.3% | √âpoque: 83/150 | Perte: 0.0032 |  0:00:16 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 56.0% | √âpoque: 84/150 | Perte: 0.0031 |  0:00:16 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 56.7% | √âpoque: 85/150 | Perte: 0.0030 |  0:00:16 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 57.3% | √âpoque: 86/150 | Perte: 0.0030 |  0:00:17 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 58.0% | √âpoque: 87/150 | Perte: 0.0030 |  0:00:17 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 58.7% | √âpoque: 88/150 | Perte: 0.0031 |  0:00:17 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 59.3% | √âpoque: 89/150 | Perte: 0.0030 |  0:00:17 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 60.0% | √âpoque: 90/150 | Perte: 0.0029 |  0:00:17 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 60.7% | √âpoque: 91/150 | Perte: 0.0029 |  0:00:17 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 61.3% | √âpoque: 92/150 | Perte: 0.0029 |  0:00:18 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 62.0% | √âpoque: 93/150 | Perte: 0.0028 |  0:00:18 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 62.7% | √âpoque: 94/150 | Perte: 0.0027 |  0:00:18 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 63.3% | √âpoque: 95/150 | Perte: 0.0028 |  0:00:18 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 64.0% | √âpoque: 96/150 | Perte: 0.0028 |  0:00:18 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 64.7% | √âpoque: 97/150 | Perte: 0.0027 |  0:00:19 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 65.3% | √âpoque: 98/150 | Perte: 0.0028 |  0:00:19 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 66.0% | √âpoque: 99/150 | Perte: 0.0026 |  0:00:19 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 66.7% | √âpoque: 100/150 | Perte: 0.0026 |  0:00:19 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 67.3% | √âpoque: 101/150 | Perte: 0.0026 |  0:00:19 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 68.0% | √âpoque: 102/150 | Perte: 0.0025 |  0:00:20 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 68.7% | √âpoque: 103/150 | Perte: 0.0025 |  0:00:20 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 69.3% | √âpoque: 104/150 | Perte: 0.0025 |  0:00:20 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 70.0% | √âpoque: 105/150 | Perte: 0.0024 |  0:00:20 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 70.7% | √âpoque: 106/150 | Perte: 0.0024 |  0:00:20 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 71.3% | √âpoque: 107/150 | Perte: 0.0024 |  0:00:21 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 72.0% | √âpoque: 108/150 | Perte: 0.0023 |  0:00:21 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 72.7% | √âpoque: 109/150 | Perte: 0.0024 |  0:00:21 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 73.3% | √âpoque: 110/150 | Perte: 0.0024 |  0:00:21 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 74.0% | √âpoque: 111/150 | Perte: 0.0023 |  0:00:21 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 74.7% | √âpoque: 112/150 | Perte: 0.0023 |  0:00:22 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 75.3% | √âpoque: 113/150 | Perte: 0.0023 |  0:00:22 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 76.0% | √âpoque: 114/150 | Perte: 0.0022 |  0:00:22 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 76.7% | √âpoque: 115/150 | Perte: 0.0022 |  0:00:22 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 77.3% | √âpoque: 116/150 | Perte: 0.0022 |  0:00:23 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 78.0% | √âpoque: 117/150 | Perte: 0.0022 |  0:00:23 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 78.7% | √âpoque: 118/150 | Perte: 0.0022 |  0:00:23 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 79.3% | √âpoque: 119/150 | Perte: 0.0021 |  0:00:23 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 80.0% | √âpoque: 120/150 | Perte: 0.0021 |  0:00:23 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 80.7% | √âpoque: 121/150 | Perte: 0.0020 |  0:00:24 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 81.3% | √âpoque: 122/150 | Perte: 0.0021 |  0:00:24 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 82.0% | √âpoque: 123/150 | Perte: 0.0020 |  0:00:24 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 82.7% | √âpoque: 124/150 | Perte: 0.0020 |  0:00:24 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë] 83.3% | √âpoque: 125/150 | Perte: 0.0020 |  0:00:24 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë] 84.0% | √âpoque: 126/150 | Perte: 0.0020 |  0:00:25 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë] 84.7% | √âpoque: 127/150 | Perte: 0.0019 |  0:00:25 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë] 85.3% | √âpoque: 128/150 | Perte: 0.0019 |  0:00:25 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë] 86.0% | √âpoque: 129/150 | Perte: 0.0019 |  0:00:25 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë] 86.7% | √âpoque: 130/150 | Perte: 0.0019 |  0:00:25 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë] 87.3% | √âpoque: 131/150 | Perte: 0.0019 |  0:00:26 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë] 88.0% | √âpoque: 132/150 | Perte: 0.0018 |  0:00:26 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë] 88.7% | √âpoque: 133/150 | Perte: 0.0018 |  0:00:26 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë] 89.3% | √âpoque: 134/150 | Perte: 0.0018 |  0:00:26 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë] 90.0% | √âpoque: 135/150 | Perte: 0.0018 |  0:00:26 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë] 90.7% | √âpoque: 136/150 | Perte: 0.0018 |  0:00:27 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë] 91.3% | √âpoque: 137/150 | Perte: 0.0017 |  0:00:27 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë] 92.0% | √âpoque: 138/150 | Perte: 0.0017 |  0:00:27 / ~0:00:29\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë] 92.7% | √âpoque: 139/150 | Perte: 0.0017 |  0:00:27 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë] 93.3% | √âpoque: 140/150 | Perte: 0.0017 |  0:00:28 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë] 94.0% | √âpoque: 141/150 | Perte: 0.0016 |  0:00:28 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë] 94.7% | √âpoque: 142/150 | Perte: 0.0017 |  0:00:28 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë] 95.3% | √âpoque: 143/150 | Perte: 0.0016 |  0:00:28 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë] 96.0% | √âpoque: 144/150 | Perte: 0.0016 |  0:00:28 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë] 96.7% | √âpoque: 145/150 | Perte: 0.0016 |  0:00:29 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë] 97.3% | √âpoque: 146/150 | Perte: 0.0016 |  0:00:29 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë] 98.0% | √âpoque: 147/150 | Perte: 0.0015 |  0:00:29 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë] 98.7% | √âpoque: 148/150 | Perte: 0.0015 |  0:00:29 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë] 99.3% | √âpoque: 149/150 | Perte: 0.0015 |  0:00:29 / ~0:00:30\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100.0% | √âpoque: 150/150 | Perte: 0.0015 |  0:00:30 / ~0:00:30\n",
      "\n",
      "============================================================\n",
      "‚úÖ ENTRA√éNEMENT TERMIN√â en 0:00:30\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELLULE 14: Entra√Ænement\n",
    "# ============================================\n",
    "# D√©finition de la fonction de perte\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "# Passage du mod√®le en mode entra√Ænement\n",
    "transformer.train()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üöÄ D√âBUT DE L'ENTRA√éNEMENT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Nombre d'√©poques (plus √©lev√© pour GPU)\n",
    "nb_epochs = 100 if device.type == \"cuda\" else 150\n",
    "print(f\"Nombre d'√©poques: {nb_epochs}\")\n",
    "print(f\"Optimiseur: {OPTIMISEUR_CHOISI}\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "temps_debut_entrainement = time.time()\n",
    "\n",
    "try:\n",
    "    for epoch in range(nb_epochs):\n",
    "        debut_epoch = time.time()\n",
    "        \n",
    "        # R√©initialisation des gradients\n",
    "        optimiser.zero_grad()\n",
    "        \n",
    "        # Passage en avant\n",
    "        sortie = transformer(src_donnees, tgt_donnees[:, :-1])\n",
    "        \n",
    "        # Calcul de la perte\n",
    "        perte = criterion(sortie.contiguous().view(-1, taille_vocab_tgt),\n",
    "                       tgt_donnees[:, 1:].contiguous().view(-1))\n",
    "        \n",
    "        # R√©tropropagation\n",
    "        perte.backward()\n",
    "        \n",
    "        # Mise √† jour des poids\n",
    "        optimiser.step()\n",
    "        \n",
    "        # Affichage de la progression\n",
    "        temps_ecoule = time.time() - temps_debut_entrainement\n",
    "        afficher_progression(epoch, nb_epochs, temps_ecoule, perte.item())\n",
    "        \n",
    "        # Lib√©ration de la m√©moire GPU si n√©cessaire\n",
    "        if device.type == \"cuda\" and epoch % 150 == 0:\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "except RuntimeError as e:\n",
    "    if \"out of memory\" in str(e) or \"not enough memory\" in str(e):\n",
    "        print(\"\\n‚ùå ERREUR: M√©moire insuffisante!\")\n",
    "        print(\"üí° Solutions:\")\n",
    "        print(f\"   - R√©duisez 'taille_batch' (actuellement: {taille_batch})\")\n",
    "        print(f\"   - R√©duisez 'longueur_seq' (actuellement: {longueur_seq})\")\n",
    "        print(\"   - R√©duisez 'nb_couches' ou 'd_modele'\")\n",
    "        if device.type == \"cuda\":\n",
    "            print(\"   - Lib√©rez la m√©moire GPU: torch.cuda.empty_cache()\")\n",
    "    raise e\n",
    "\n",
    "temps_fin_entrainement = time.time()\n",
    "temps_total_entrainement = temps_fin_entrainement - temps_debut_entrainement\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"‚úÖ ENTRA√éNEMENT TERMIN√â en {formater_temps(temps_total_entrainement)}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6fac6dd-fe68-4606-a021-f450dae60c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç D√âBUT DE LA VALIDATION...\n",
      "G√©n√©ration des donn√©es de validation (batch=4, seq=128)...\n",
      "‚úì Perte de Validation: 10.1278\n",
      "‚úì Temps de validation: 0.06s\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELLULE 15: Validation\n",
    "# ============================================\n",
    "print(\"\\nüîç D√âBUT DE LA VALIDATION...\")\n",
    "debut_validation = time.time()\n",
    "\n",
    "transformer.eval()\n",
    "\n",
    "# G√©n√©ration de donn√©es de validation\n",
    "print(f\"G√©n√©ration des donn√©es de validation (batch={taille_batch}, seq={longueur_seq})...\")\n",
    "val_src_donnees = torch.randint(1, taille_vocab_src, (taille_batch, longueur_seq)).to(device)\n",
    "val_tgt_donnees = torch.randint(1, taille_vocab_tgt, (taille_batch, longueur_seq)).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    val_sortie = transformer(val_src_donnees, val_tgt_donnees[:, :-1])\n",
    "    perte_val = criterion(val_sortie.contiguous().view(-1, taille_vocab_tgt),\n",
    "                        val_tgt_donnees[:, 1:].contiguous().view(-1))\n",
    "\n",
    "fin_validation = time.time()\n",
    "temps_validation = fin_validation - debut_validation\n",
    "\n",
    "print(f\"‚úì Perte de Validation: {perte_val.item():.4f}\")\n",
    "print(f\"‚úì Temps de validation: {temps_validation:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b292bb8-a2be-4f02-baff-4f1ef7980340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üìä R√âSUM√â DE L'EX√âCUTION\n",
      "============================================================\n",
      "üñ•Ô∏è  Device utilis√©: cpu\n",
      "üéØ Optimiseur: Adam\n",
      "üì¶ Taille batch: 4\n",
      "üìè Longueur s√©quence: 128\n",
      "üî¢ Nombre de param√®tres: 9,374,600\n",
      "\n",
      "‚è±Ô∏è  Temps d'initialisation: 0.10s\n",
      "‚è±Ô∏è  Temps d'entra√Ænement: 0:00:19\n",
      "‚è±Ô∏è  Temps de validation: 0.06s\n",
      "‚è±Ô∏è  Temps total: 0:01:50\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELLULE 16: R√©sum√© final\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä R√âSUM√â DE L'EX√âCUTION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"üñ•Ô∏è  Device utilis√©: {device}\")\n",
    "if device.type == \"cuda\":\n",
    "    print(f\"üíæ M√©moire GPU finale: {torch.cuda.memory_allocated(device) / (1024**2):.2f} MB\")\n",
    "    print(f\"üíæ M√©moire GPU max: {torch.cuda.max_memory_allocated(device) / (1024**2):.2f} MB\")\n",
    "print(f\"üéØ Optimiseur: {OPTIMISEUR_CHOISI}\")\n",
    "print(f\"üì¶ Taille batch: {taille_batch}\")\n",
    "print(f\"üìè Longueur s√©quence: {longueur_seq}\")\n",
    "print(f\"üî¢ Nombre de param√®tres: {nb_parametres:,}\")\n",
    "print(f\"\\n‚è±Ô∏è  Temps d'initialisation: {fin_init - debut_init:.2f}s\")\n",
    "print(f\"‚è±Ô∏è  Temps d'entra√Ænement: {formater_temps(temps_total_entrainement)}\")\n",
    "print(f\"‚è±Ô∏è  Temps de validation: {temps_validation:.2f}s\")\n",
    "print(f\"‚è±Ô∏è  Temps total: {formater_temps(time.time() - debut_init + (fin_init - debut_init))}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73cbe25-ce16-41bf-abe5-72801c279f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Transformer GPU)",
   "language": "python",
   "name": "transformer_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
